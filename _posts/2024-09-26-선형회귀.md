---
layout: single
title : "Linear Regression - 선형회귀"
categories: Machine_Learning
tag: [basic, ml, ai]
author_profiles: false
sidebar:
    nav: "counts" #doc 도 존재
# search: false #검색 원하지 않은 포스트의 경우
use_math: true #Latex 문법 사용 => 수식사 용
---

**공지사항** [해당 포스트는 선형 대수학의 기초를 어느정도 알고 있다는 가정하에 진행합니다. 혹시 선형대수학에 대해 조금 더 알고 싶으신 분들은 아래 링크의 동영상을 한번 봐 주시면 도움이 될 것 같습니다.]
{: .notice--info}
[선형대수학의 본질| 3b1b](https://www.youtube.com/watch?v=ic_hG2M2nG0&list=PLkoaXOTFHiqhVDo0nWybNmihCP_4BjOFR){: .btn .btn--danger}


<div class='notice'>
표현력, 이미지 부족으로 해당 포스트는 추가 업뎃이 이루어집니다...
</div>

## 선형 회귀 Linear Regression


### 1.1 선형 회귀의 의미

우선 선형회귀를 알기 위해서 단어를 쪼개서 접근해보자. 

Regression = 회귀 : 과거의 상태로 돌아간다는 의미를 가지고 있다.

Linear = 선형 : 선이 이어져 있다는 의미를 가지고 있다.

그래서 일반적으로 조합하여 생각하면 선형회귀에 대해 이런 생각이 나온다.

Linear Regression = 선형회귀 : 과거의 상태로 돌아가지만 선이 이어져 있다, 이는 양 끝단, 즉 과거와 미래 사이에 현재를 제외하고 연관성이 존재한다는 의미로 생각하면 좋을 것 같다. 


### 1.2 머신러닝에서의 관점

Machine Learning 의 관점에서 선형회귀를 보면 과거의 상태로 돌아간다는 관점을 어떻게 보면 될까?

Machine Learning 모델은 input 이 들어가서 Output 이 나오는 형태의 모델이다 우리가 모델을 사용할때 데이터를 넣고 데이터에 대한 결과물을 얻기 위해 모델을 사용한다. 

이때 선형회귀는 input과 output 을 연결하게 되고 이로 하여금 두 사이의 관계성, 연관성을 추정 가능하게 한다

머신러닝에서 이런 input 과 output 사이의 선형적 관계가 존재하고 이러한 두 결과에 대한 관계를 분석하는 방식을 회귀 분석이라 정의하며 Linear Regression 의 방법론으로 접근한다.

**즉 머신러닝의 목표는 input 과 output 사이의 관계를 정의하며 해당 정의에 대한 수식을 변경함으로써 input 에 대하여 원하는 output 의 형태를 만들도록 정의하는 것이다.**

만일 해당 내용이 잘 인지가 안된다면 좀 더 간단하게 접근해보면 

어떠한 입력에 대한 원하는 결과를 얻기 위해 중간 과정에서 개입할것이다. 이때 어떻게 개입할지, 개입 방식 및 개입 정도를 정할때 입력과 결과의 관계가 개입에 따라 어떻게 바뀌는지 보고 수정해 나가는 것이다.


### 1.3 Linear Regression 의 가정

선형회귀를 사용할때 꼭 필요한 요소는 아래와 같다.

선형성 : 종속 변수와 독립 변수의 관계는 선형적이어야 한다. 

독립성 : 관측값들은 서로 독립적이어야 하며 잔차들은 무작위로 분포되어야 한다

등분산성 : 잔차들이 일정한 분포를 보여야 한다.  
    특정 구간에서 잔차의 분산이 커지거나 작아지면 안된다.

정규성 : 오류가 정규 분포를 따른다. 
    잔차들이 정규 분포를 따를 경우 점들이 대각선에 가깝게 위치한다.

해당 내용은 확률 통계의 기초 부분이나 좀더 디테일하게 접근해 보면 다음과 같다

#### 선형성 

input 와 output 은 서로 관계가 끊임 없이 존재해야 한다 이는 input(독립변수)이/가 변할때  output(종속변수) 도 변해야 한다는 것을 의미합니다. 

#### 독립성

우리가 학습 데이터로 사용해야 하는 관측값 들이 서로 독립적이여야 한다는 의미입니다. 

이때 관측값에 대해 좀 더 자세히 설명하면 데이터의 형태에서 csv , 데이터 프레임의 형태에서 데이터 들이 있는 행을 의미합니다. 

예시로 우리가 아래 표에서 

| 나이  | 지역  | 연봉  |
|-------|-------|------|
|  20   | 서울  |  3000 |
|  30   | 경기  | 4000 |
|  40   | 부산  | 5000 |

하나의 행 (20, 서울 , 30000) 이 관측값이고,
피처는  (20,30,40) 의 열입니다. 

그러므로 서로 행들이 독립적이라고 생각하면 좋을 것 같습니다.


#### 등분산성 

우선 잔차(Residual)는 실제 값과 모델이 예측한 값 즉 모델에서 input 을 넣었을때 나오는 값과 실제 값 사이의 오차를 의미한다. 즉, 잔차는 모델이 데이터를 어느정도 설명하는지를 보여준다. 

등분산성이란 이러한 잔차의 분산(잔차의 퍼짐의 정도) 가 일정해야 한다고 설명된다.
그러니깐 피처가 변함에 따라 잔차의 크기가 변화해서는 안된다고 의미하는 것이다.

이러한 잔차의 분산이 일정(등분산성) 이 성립되지 않으면 모델이 특정 범위에서 매우 크거나 작은 오차를 발생시키며 이는 모델의 왜곡을 유발하는 요소이다.


####  정규성

잔차들이 정규분포를 따라야 한다는 가정이다.

여기서 정규분포란 데이터가 평균을 중심으로 대칭적으로 퍼져 있는 분포의 형태를 말한다.
데이터의 대부분이 중심(평균 근처) 에 몰려 있으며 양쪽으로 갈수록 빈도가 점점 줄어든다.

잔차가 정규 분포를 따를 경우 회귀분석에서 구한 통계량들이 유의미하게 해석될수 있다 

왜 그런것이나면 결국 모델은 잔차를 통해서 학습을 하게 되는데 이 잔차의 분포가 중심이 아닌 한쪽으로 쏠리게 되면 회귀모델이 특정 범위에서 과대, 과소 예측할 가능성이 높아진다. 

그래서 잔차의 분포는 정규분포를 따라야 한다.








